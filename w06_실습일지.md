# SSWU_20190224_CSM 구세원 

컴퓨터 시스템 관리 6주차 실습일지입니다.

### *실습과제 결과*

- server(b)에 LVM을 설치하는 과제를 수행하였다. 

1) 우선 `lvm lvdisplay`명령어로 LV 상태를 출력했다. 

![실습과제1_lvdisplay](https://user-images.githubusercontent.com/65717358/114351706-efcc8800-9ba5-11eb-9afd-96ec6c7394f1.PNG)

![실습과제2_lvdisplay](https://user-images.githubusercontent.com/65717358/114352054-5baef080-9ba6-11eb-9489-0754e5582efc.PNG)


2) `df`와 `cd /lvm1`, `ls -l` 명령어를 사용하여 각 LV가 마운트된 디렉터리와 그 디렉터리에 LV 속 파일(testFile)까지 모두 정상적으로 마운트되었는지 확인하였다. 

![실습과제3_df,lvm](https://user-images.githubusercontent.com/65717358/114352120-71bcb100-9ba6-11eb-8aab-b314ba530fa0.PNG)

 
 
## 1. 새로 배운 내용

### 1.1 디스크 관리 : RAID 6, RAID 1+0, RAID 1+6

### *이론* 
 1) RAID 6 
- RAID 5를 개선한 형태로 패리티가 1개인 RAID 5와 달리 패리티 디스크가 2개이다. (총 하드디스크 - 2 = 실제 이용가능한 디스크 개수)
- RAID 5보다 안전성은 높아졌지만 패리티가 2개이기에 공간효율성과 성능(속도)은 낮다. 
- 최소 4개 이상의 하드디스크가 필요함. 

 2) RAID 1+0
- RAID 1의 안전성과 RAID 0의 속도를 모두 잡은 케이스이다. 
- 디스크 입장에선 RAID 1로 두 개씩 짝을 짓고 그것들을 다 묶어 RAID 0을 만든다. (데이터 입장에선, 우선 데이터를 RAID 0에 따라 두 그룹으로 나누고 각 그룹에서 RAID1의 형태를 취한 형태) 
- RAID 1이 있어 여전히 공간효율성이 50%에 미친다. 

 3) RAID 1+6
- 안전성이 큰 특징인 RAID 1과 RAID 6을 합친 형태로 그 무엇보다도 안전성을 우선순위로 둔 형태이다. 성능(속도)와 공간효율성이 아닌 안전성만을 오직 고려하는 아주 중요한 데이터를 처리할 때 이용하게 된다. 


### *실습* 
 1) RAID 1+0 구성
  > apt install mdadm 
  > 
  > mdadm --create /dev/md2 --level=1 --raid-devices=2 /dev/sdb1 /dev/sdc1 : sdc1, sd2를 md2라는 raid1으로 생성
  > 
  > mdadm --create /dev/md10 --level=0 --raid-devices=2 /dev/md2/ /dev/md3 : raid1인 md2와 md3를 raid0으로 생성 
  > 
  > mkfs -t ext4 /dev/md10 : 파일 시스템 생성
  > 
  > mkdir /raid10 
  > 
  > mount /dev/md10 /raid10
  > 
  > df : 마운트 상황 확인 

  > cp /boot/vmlinuz /raid10/testFile : raid10에 적당한 크기의 파일 복사 
  
  > vi /etc/fstab : 부팅 시 자동으로 마운트되도록 설정 
  
  > mdadm --detail --scan > file.txt
  > 
  > gedit file.txt : 이때, 해당 텍스트 파일 내용 모두 복사 
  > 
  > gedit /etc/mdadm/mdadm.conf 에 위에서 복사한 내용 붙여넣기 + `name = server : 숫자` 부분 삭제
  > 
  > update-initramfs -u :위에서 설정한 내용 적용
  > 
  > reboot  
  > 
  > ls -l /dev/md* : md로 시작하는 장치들에 관한 정보 

 2) RAID 1+0 문제 발생 후 복구 시 오류 발생 
 
 - 아래와 같이 md2가 어디선가 작동중이라는 메시지가 뜬다. 
 
 ![md02가 현재 어딘가에서 계속 실행 중이기 때문에 md10을 생성할 때 제대로 적용되지 않고 있다](https://user-images.githubusercontent.com/65717358/114354630-72a31200-9ba9-11eb-90ee-93949aaa27c0.PNG)

 
 > `ls /dev/md*` : 설치된 장치를 모두 확인할 수 있으며 이때 md127이란 생소한 장치를 발견할 수 있다. 처음에 만들었던 md10이 md127로 변한 것. = md127의 작동을 멈추어야 md2를 사용가능
 > 
 > `mdadm --stop /dev/md127`
 > 
 > `nano file.txt` 내용 복사
 > 
 > `vi /etc/mdadm/mdadm.conf` 맨 마지막에 붙여넣기, `name = server : ` 부분 모두 지우기. (`name = server : 10`으로 되어 있어 md127로 오류가 발생했던것)
 > 
 > update-initramfs -u : 위의 내용 업데이트 

---
### 1.2 LVM(Logical Volume Management)

### *이론*  
 
- 하드디스크를 논리적 볼륨 단위로 관리하며 디스크 본래의 용량을 여러 개로  유동적인 디스크 관리를 할 수 있다. 
- 전통적인 시스템에선 파일 시스템과 저장장치가 직접 소통하여 시간이 오래 걸린다는 단점이 있다. LVM 기반 시스템에선 파일 시스템과 저장장치 사이에 있는 LVM 시스템이 파일을 논리적인 단위로 접근할 수 있도록 해주어 처리 시간이 줄어든다. 또한 RAID가 파티션 된 디스크 단위로 처리를 한다면 LVM은 논리 단위로 관리한다. 
- 관련 용어는 간단하게 정리하여 아래와 같으며 추가적인 내용은 [3. 참고 내용](https://github.com/sayone99/SSWU_20190224_CSM/blob/main/w07_%EC%8B%A4%EC%8A%B5%EC%9D%BC%EC%A7%80.md#3-%EC%B0%B8%EA%B3%A0-%EB%82%B4%EC%9A%A9)에서 더욱 자세히 살펴볼 수 있다.  
 > PV(Physical Volume) : 파티션 된 하드 디스크
 > 
 > VG = PV1 + PV2 + ... 
 > 
 > PV1 = PE1 + PE1 + ... 
 > 
 > LE (Logical Extent) : PV를 구성하는 블록으로 PE와 대응하며 크기도 같다
 > 
 > LV = LE + LE + ... 
 
 ### *실습* LVM 구성하기
 - PV 생성
  > pvcreate /dev/sdb1 
  > 
  > pvcreate /dev/sdc1 
 
 - VG 생성
  > lvm vgcreate myVG /dev/sdb1 /dev/sdc1
  > 
  > lvm vgdisplay : VG 확인
 
 - LV 생성 
  > lvcreate -L 1G -n myLV1 myVG
  > 
  > lvcreate -L 3G -n myLV2 myVG
  > 
  > lvcreate -l 100%FREE --n myLV3 myVG
  > 
  > ls - l /dev/myVG
 
 - LV에 파일시스템 생성
  > mkfs -t ext4 /dev/myVG/myLV1 
  > 
  > mkfs -t ext4 /dev/myVG/myLV2
  > 
  > mkfs -t ext4 /dev/myVG/myLV3
  
 - LV 마운트 
  > mkdir /lvm1 /lvm2 /lvm3
  >  
  > mount /dev/myVG/myLV1 /lvm1 
  > 
  > mount /dev/myVG/myLV2 /lvm2 
  > 
  > mount /dev/myVG/myLV3 /lvm3 
  > 
  > cp /boot/vmlinuz /lvm1/testFile
  > 
  > cp /boot/vmlinuz /lvm2/testFile
  > 
  > cp /boot/vmlinuz /lvm3/testFile

- 부팅 시 자동으로 마운트 

---
### 1.3 Quota 쿼터 

### *이론* 
- 개인 사용자별로 사용가능한 용량을 할당해주는 것을 Quota 쿼터라고 한다. 쿼터를 설정해놓으면 사용자가 루트 파일에 접근하지 않은 상태로 파일 시스템을 이용할 수 있기 때문에 시스템 유지 측면에서도 안전하다. 루트 파일을 사용하지 않기 때문에 관리자와 작업 경로가 겹칠 일이 없다는 것 또한 시스템을 유지하기에 좋다. 

### *실습*
- 사용자 생성 : 사용자별로 용량(크기)을 할당해주는 것이므로 사용자 생성이 우선. 
 > adduser --home /userHome/user01 user01
 > 
 > adduser --home /userHome/user02 user02 

- 쿼터용 장치 설정 : 쿼터용으로 사용할 장치를 설정해준다. 
 > vi /etc/fstab 
 > 
 > /dev/sdb1 
	> ~~ dafaults, usrjquota=aquota.user, jqfmt=vfsv0 
- /userHome 재마운트 : 위에서 쿼터용 장치를 설정했으므로 재부팅해주는 개념으로 재마운트 한다. 
 > mount --options remount /userHome 
 > 
 > mount 

- 쿼터 설정 : 쿼터 DB를 생성해야 쿼터가 설정된다. 
- 사용자별 공간 할당 
 > - edquota -u user01 : -u는 사용자별 할당, -g는 그룹별 쿼터 설정이다. 
 > 
 > - soft limit와 hard limit가 존재하는데, soft limit은 명시되어 있는 hard limit를 넘었을 때 저장가능한 최대 한계이다. 며칠 간의 유예기간 동안 hard limit 이상~ soft limit 이하의 용량을 사용할 수 있다. 하지만 유예기간이 지난 후엔 hard limit 까지의 데이터만 저장되므로 그 안에 파일을 정리해야 한다. 

- 용량 제한 확인 
 > su - user01 : user01의 용량 제한을 확인하기 위해선 user01로 로그인 해야 한다. 
 > 
 > cp /boot/vmlinuz test1 : 이렇게 test2, test3을 하면 용량제한이라고 되어 있다. 이런 방식으로 용량 제한이 어떻게 되는지 확인할 수 있다. 
 > 
 > repquota /userHome : 사용자별 현재 사용량을 확인할 수 있다. 



## 2. 발생한 문제/고민한 점 및 해결방법

- [3. 참고내용 - 1)] RAID 6의 구성이 궁금해 직접 찾아보았다. 특히 패리티가 2개가 글로는 어떤 모습인지 상상이 잘 안되서 이미지를 참고하였다. 패리티 정보가 한 디스크에서 2개의 블록을 차지하기 때문에 디스크가 최대 2개까지 손상되어도 데이터 보안은 유지할 수 있다는 점을 확실히 알 수 있었다. 

- [3. 참고내용 - 2)] 내가 생각한 LE와 PE의 차이점이 정확한지 궁금해 직접 찾아보았고 제대로 이해하고 있다는 것을 확인할 수 있었다. PE와 LE는 일정한 크기의 블록이고 상호 대응하고 있다. 다만 PE는 PV에 따라 구분된다, 즉 소속?이 있다는 것이 특징이고 (PV1의 PE들, PV2의 PE들 이런식으로!) LE는 이런 구분없는 PE와 동일크기의 블럭이다.  

- LVM에서 LV끼리 RAID로 묶을 순 없나? 라는 고민을 하게 되었다. RAID 6이나 RAID1로는 신뢰성을 얻을 수 있는 것에 반해 LVM으로는 안전성이 제대로 확보되지 않을 거라 생각했기 때문이다. LVM과 RAID는 디스크를 관리하는 단위 자체가 다르기 때문에 시작부터 가능하지 않는다는 점을 깨달았고, LV는  Linear LV , striped LV , Mirrored LV 와 같이 데이터 저장 방식에 따라 보안 유지를 설정할 수 있음을 복습하며 다시 깨달았다. 



## 3. 참고 내용

1) RAID의 종류 대부분 : https://www.lacie.co.kr/education/lacie-raid-manager/raid/ 
   
   RAID 6 : https://www.ibm.com/docs/ko/power6?topic=POWER6/arebk/raidsix.htm	

2) LVM의 구성요소 : https://tech.cloud.nongshim.co.kr/2018/11/23/lvmlogical-volume-manager-1-%EA%B0%9C%EB%85%90/ 


## 4. 회고    
    
### 4.1 좋았던 점 +
	
- 단일 RAID 뿐만 아니라 중첩 RAID까지 배워보면서 RAID의 고급 설정까지 해낼 수 있었다는 점이 뿌듯했다. 또한 LVM을 배우면서 물리적인 하드디스크와 디스크 초기 용량과 상관없이 임의로 디스크 용량을 재분배할 수 있다는 점이 신기했다. 리눅스를 사용하면서 디스크의 용량을 자유롭게 조절할 수 있다면 파일을 관리할 때 훨씬 더 유용할 것이다. 

### 4.2 아쉬웠던 점 -
	
- 쿼터부분에서 명령어가 어려워 많이 헷갈렸다. 또한 오류가 많이 발생해 어떤 오류를 해결하고 있는 것인지 제대로 파악하지 못하는 경우도 많았다는 점에서 이 부분에 대해 적극적으로 찾아보지 못해 아쉽다. 수업 전 남은 시간동안 쿼터에 대해 조금 더 자세히 찾아볼 필요가 있을 듯 하다. 
  
### 4.3 새로 깨달은 점 !

- 실무에서 리눅스를 활용하는 이유는, 윈도우나 맥OS보다 시스템 관리가 편리하기 때문이라는 것을 다시 한번 깨닫게 되었다. 윈도우나 맥OS의 관리자 입장이 되어 본 적은 없어 정확한 비교를 할 수는 없지만 리눅스에선 책의 한 챕터 정도 되는 내용으로 디스크를 관리하고 사용자별로 저장 용량을 제한하는 방법을 배울 수 있다는 점이 리눅스의 큰 장점이라는 것을 확신했다. 또한 리눅스 자체가 오픈 소스라서 mdadm이나 lvm, quota에서 발생하는 오류들을 이미 많은 사람들이 겪고 이를 인터넷으로 공유하고 있다는 것이 가장 큰 장점일 것이다. 
